{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "import pmlb as dsets\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "from os.path import join as oj\n",
    "from copy import deepcopy\n",
    "import pandas as pd\n",
    "from numpy import array as arr\n",
    "\n",
    "# sklearn models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from scipy import interpolate\n",
    "from sklearn.tree import export_graphviz, DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.tree import plot_tree\n",
    "\n",
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train an rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = 4\n",
    "np.random.seed(13)\n",
    "N = 100\n",
    "X = np.random.rand(N, num_features)\n",
    "# y = np.logical_xor(X[:, 0] > 0.5, X[:, 1] > 0.5)\n",
    "y = np.random.rand(N)\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y)\n",
    "\n",
    "plt.show()\n",
    "rf = DecisionTreeRegressor(max_depth=30)\n",
    "rf.fit(X, y)\n",
    "print(rf.score(X, y))\n",
    "plt.scatter(X[:, 0], X[:, 1], c=rf.predict(X))\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# plot_tree(rf.estimators_[0])\n",
    "# plot_tree(rf)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# convert to a DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calc_more(n_nodes, children_left, children_right):\n",
    "    # The tree structure can be traversed to compute various properties such\n",
    "    # as the depth of each node and whether or not it is a leaf.\n",
    "    node_depth = np.zeros(shape=n_nodes, dtype=np.int64)\n",
    "    is_leaves = np.zeros(shape=n_nodes, dtype=bool)\n",
    "\n",
    "\n",
    "    # calculate node_depth and is_leaves\n",
    "    stack = [(0, -1)]  # seed is the root node id and its parent depth\n",
    "    while len(stack) > 0:\n",
    "        node_id, parent_depth = stack.pop()\n",
    "        node_depth[node_id] = parent_depth + 1\n",
    "\n",
    "        # If we have a test node\n",
    "        if (children_left[node_id] != children_right[node_id]):\n",
    "            stack.append((children_left[node_id], parent_depth + 1))\n",
    "            stack.append((children_right[node_id], parent_depth + 1))\n",
    "        else:\n",
    "            is_leaves[node_id] = True\n",
    "            \n",
    "    return node_depth, is_leaves\n",
    "\n",
    "\n",
    "\n",
    "stack = [(0, -1)]  # seed is the root node id and its parent depth\n",
    "while len(stack) > 0:\n",
    "    node_id, parent_depth = stack.pop()\n",
    "    node_depth[node_id] = parent_depth + 1\n",
    "\n",
    "    # If we have a test node\n",
    "    if (children_left[node_id] != children_right[node_id]):\n",
    "        stack.append((children_left[node_id], parent_depth + 1))\n",
    "        stack.append((children_right[node_id], parent_depth + 1))\n",
    "    else:\n",
    "        is_leaves[node_id] = True\n",
    "\n",
    "estimator = rf\n",
    "# The decision estimator has an attribute called tree_  which stores the entire\n",
    "# tree structure and allows access to low level attributes. The binary tree\n",
    "# tree_ is represented as a number of parallel arrays. The i-th element of each\n",
    "# array holds information about the node `i`. Node 0 is the tree's root. NOTE:\n",
    "# Some of the arrays only apply to either leaves or split nodes, resp. In this\n",
    "# case the values of nodes of the other type are arbitrary!\n",
    "#\n",
    "# Among those arrays, we have:\n",
    "#   - left_child, id of the left child of the node\n",
    "#   - right_child, id of the right child of the node\n",
    "#   - feature, feature used for splitting the node\n",
    "#   - threshold, threshold value at the node\n",
    "#\n",
    "\n",
    "n_nodes = estimator.tree_.node_count\n",
    "children_left = estimator.tree_.children_left\n",
    "children_right = estimator.tree_.children_right\n",
    "feature = estimator.tree_.feature\n",
    "threshold = estimator.tree_.threshold\n",
    "num_leaves = estimator.tree_.n_leaves\n",
    "num_non_leaves = estimator.tree_.node_count - num_leaves\n",
    "node_depth, is_leaves = calc_more(n_nodes, children_left, children_right)\n",
    "values = estimator.tree_.value\n",
    "\n",
    "\n",
    "'''\n",
    "recursively store all leaf paths into a dictionary as tuples of (node_idxs, weight)\n",
    "weight is -1/+1 depending on if it left/right\n",
    "running_list is a reference to one list which is shared by all calls!\n",
    "'''\n",
    "all_leaf_paths = {}\n",
    "def calc_all_leaf_paths(node_idx, n_nodes, children_left, children_right, running_list):\n",
    "    \n",
    "#     print('at', node_idx)\n",
    "    \n",
    "    # check if we are at a leaf\n",
    "    if children_left[node_idx] == children_right[node_idx]:\n",
    "        all_leaf_paths[node_idx] = deepcopy(running_list)\n",
    "    else:\n",
    "        running_list.append((node_idx, -1)) # assign weight of -1 to left\n",
    "        calc_all_leaf_paths(children_left[node_idx], n_nodes, children_left, children_right, running_list)\n",
    "        running_list.pop()        \n",
    "        running_list.append((node_idx, +1)) # assign weight of +1 to right\n",
    "        calc_all_leaf_paths(children_right[node_idx], n_nodes, children_left, children_right, running_list)\n",
    "        running_list.pop()\n",
    "            \n",
    "calc_all_leaf_paths(0, n_nodes, children_left, children_right, running_list=[])\n",
    "# all_leaf_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, num_features, num_non_leaves, num_leaves):\n",
    "        super(Net, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(num_features, num_non_leaves),\n",
    "            nn.Linear(num_non_leaves, num_leaves), \n",
    "            nn.Linear(num_leaves, 1, bias=False)\n",
    "        )\n",
    "        \n",
    "        # 1st and second layers should be initialized to 0\n",
    "        for i in range(2):\n",
    "            self.layers[i].weight.data *= 0\n",
    "            self.layers[i].bias.data *= 0\n",
    "        \n",
    "    # assume x shape is (batch_size, ...)\n",
    "    def forward(self, x):\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = self.layers[0](x) \n",
    "#         print('lay 1 weights', self.layers[0].weight)\n",
    "\n",
    "        x[x < 0] = -1\n",
    "        x[x >= 0] = 1\n",
    "#         print('after lay 1', x)\n",
    "        \n",
    "        x = self.layers[1](x)\n",
    "        x = (x == 0).float()\n",
    "#         print('after lay 2', x)\n",
    "        \n",
    "        x = self.layers[2](x)\n",
    "#         print('after lay 3', x)\n",
    "        return x\n",
    "    \n",
    "x = torch.Tensor(X[:10])    \n",
    "net = Net(num_features, num_non_leaves, num_leaves)\n",
    "\n",
    "\n",
    "# set the first layer\n",
    "nonleaf_node_to_nonleaf_neuron_num = {} # np.zeros(num_non_leaves)\n",
    "nonleaf_neuron_num = 0\n",
    "for i in range(n_nodes):\n",
    "    if not is_leaves[i]:\n",
    "#         print(feature[i], threshold[i])\n",
    "        nonleaf_indices.append(i)\n",
    "        net.layers[0].weight.data[nonleaf_neuron_num, feature[i]] = 1\n",
    "        net.layers[0].bias.data[nonleaf_neuron_num] = -threshold[i]\n",
    "        nonleaf_node_to_nonleaf_neuron_num[i] = nonleaf_neuron_num\n",
    "        nonleaf_neuron_num += 1\n",
    "        \n",
    "# print(nonleaf_node_to_nonleaf_neuron_num)\n",
    "# print(net.layers[0].weight.data)\n",
    "\n",
    "\n",
    "\n",
    "# set the 2nd + 3rd layer\n",
    "for leaf_neuron_num, leaf_idx in enumerate(sorted(all_leaf_paths.keys())):\n",
    "    path = all_leaf_paths[leaf_idx]\n",
    "    for (nonleaf_node, sign) in path:\n",
    "        net.layers[1].weight.data[leaf_neuron_num, \n",
    "                                  nonleaf_node_to_nonleaf_neuron_num[nonleaf_node]] = sign # num_leaves x num_non_leaves\n",
    "        net.layers[1].bias.data[leaf_neuron_num] = -1 * float(node_depth[leaf_idx])\n",
    "#         print(input_neuron_num)\n",
    "    \n",
    "    # third lay\n",
    "    net.layers[2].weight.data[0, leaf_neuron_num] = values[leaf_idx][0, 0] # note, this will be multivariate for classification!\n",
    "\n",
    "    \n",
    "# test\n",
    "pred = net(x)    \n",
    "    \n",
    "device = 'cuda'\n",
    "netg = deepcopy(net).to(device)\n",
    "X_tg = deepcopy(X_t).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.isclose(rf.predict(X[:10]).flatten(), net(x).detach().numpy().flatten()).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_t = torch.Tensor(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89.1 µs ± 17.5 µs per loop (mean ± std. dev. of 7 runs, 5 loops each)\n"
     ]
    }
   ],
   "source": [
    "timeit -n 5 rf.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "560 µs ± 44 µs per loop (mean ± std. dev. of 7 runs, 5 loops each)\n"
     ]
    }
   ],
   "source": [
    "timeit -n 5 net(X_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "699 µs ± 51.2 µs per loop (mean ± std. dev. of 7 runs, 5 loops each)\n"
     ]
    }
   ],
   "source": [
    "timeit -n 5 netg(X_tg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
